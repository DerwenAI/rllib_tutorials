{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray RLlib Multi-Armed Bandits - Linear Thompson Sampling\n",
    "\n",
    "© 2019-2021, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../../images/AnyscaleAcademyLogo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lesson uses a second exploration strategy we discussed briefly in lesson [02 Exploration vs. Exploitation Strategies](02-Exploration-vs-Exploitation-Strategies.ipynb), _Thompson Sampling_, with a linear variant, [LinTS](https://docs.ray.io/en/latest/rllib-algorithms.html?highlight=greedy#linear-thompson-sampling-contrib-lints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wheel Bandit\n",
    "\n",
    "We'll use it on the `Wheel Bandit` problem ([RLlib discrete.py source code](https://github.com/ray-project/ray/blob/master/rllib/contrib/bandits/envs/discrete.py)), which is an artificial problem designed to force exploration. It is described in the paper [Deep Bayesian Bandits Showdown](https://arxiv.org/abs/1802.09127) (see _The Wheel Bandit_ section). The paper uses it to  model 2D contexts, but it can be generalized to more than two dimensions.\n",
    "\n",
    "You can visualize this problem as a wheel (circle) with four other regions around it. An exploration parameter delta $\\delta$ defines a threshold, such that if the norm of the context vector is less than or equal to delta (inside the “wheel”) then the leader action is taken (conventionally numbered `1`). Otherwise, the other four actions are explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From figure 3 in [Deep Bayesian Bandits Showdown](https://arxiv.org/abs/1802.09127), the Wheel Bandit can be visualized this way:\n",
    "\n",
    "![Wheel Bandit](../../images/rllib/Wheel-Bandit.png)\n",
    "\n",
    "The radius of the entire colored circle is 1.0, while the radius of the blue \"core\" is $\\delta$.\n",
    "\n",
    "Contexts are sampled randomly within the unit circle (radius 1.0). The optimal action for the blue, red, green, black, or yellow region is the action 1, 2, 3, 4, or 5, respectively. In other words, if the context is in the blue region, radius < $\\delta$, action 1 is optimal, if it is in the upper-right-hand quadrant with radius between $\\delta$ and 1.0, then action 2 is optimal, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter $\\delta$ controls how aggressively we explore. The reward $r$ for each action and context combination are based on a normal distribution as follows:\n",
    "\n",
    "Action 1 offers the reward, $r \\sim \\mathcal{N}({\\mu_1,\\sigma^2})$, independent of context.\n",
    "\n",
    "Actions 2-5 offer the reward, $r \\sim \\mathcal{N}({\\mu_2,\\sigma^2})$ where $\\mu_2 < \\mu_1$, _when they are suboptimal choices_. When they are optimal, the reward is $r \\sim \\mathcal{N}({\\mu_3,\\sigma^2})$ where $\\mu_3 \\gg \\mu_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to $\\delta$, the parameters $\\mu_1$, $\\mu_2$ $\\mu_3$, and $\\sigma$ are configurable. The default values for these parameters in the paper and in the [RLlib implementation](https://github.com/ray-project/ray/blob/master/rllib/contrib/bandits/envs/discrete.py) are as follows:\n",
    "\n",
    "```python\n",
    "DEFAULT_CONFIG_WHEEL = {\n",
    "    \"delta\": 0.5,\n",
    "    \"mu_1\": 1.2,\n",
    "    \"mu_2\": 1.0,\n",
    "    \"mu_3\": 50.0,\n",
    "    \"std\": 0.01  # sigma\n",
    "}\n",
    "```\n",
    "\n",
    "Note that the probability of a context randomly falling in the high-reward region (not blue) is 1 − $\\delta^2$. Therefore, the difficulty of the problem increases with $\\delta$, and algorithms used with this bandit are more likely to get stuck repeatedly selecting action 1 for large $\\delta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Wheel Bandit with Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the import in the next cell of `LinTSTrainer` and how it is used below when setting up the _Tune_ job. For the `LinUCB` example in the [previous lesson](04-Linear-Upper-Confidence-bound.ipynb), we didn't import the corresponding `LinUCBTrainer`, but passed a \"magic\" string to Tune, `contrib/LinUCB`, which RLlib already knows how to associate with the corresponding `LinUCBTrainer` implementation. Passing the class explicitly, as we do here, is an alternative. The [RLlib environments documentation](https://docs.ray.io/en/latest/rllib-env.html) discusses these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paco/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray.rllib.contrib.bandits.agents import LinTSTrainer\n",
    "from ray.rllib.contrib.bandits.agents.lin_ts import TS_CONFIG\n",
    "from ray.rllib.contrib.bandits.envs import WheelBanditEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delta': 0.5, 'mu_1': 1.2, 'mu_2': 1, 'mu_3': 50, 'std': 0.01}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbe = WheelBanditEnv()\n",
    "wbe.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effective number of `training_iterations` will be `20 * timesteps_per_iteration == 2,000` where the timesteps per iteration is `100` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for 20 time steps\n"
     ]
    }
   ],
   "source": [
    "TS_CONFIG[\"env\"] = WheelBanditEnv\n",
    "\n",
    "training_iterations = 20\n",
    "print(\"Running training for %s time steps\" % training_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's in the standard config object for _LinTS_ anyway??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 0,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': False,\n",
       " 'rollout_fragment_length': 1,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 1,\n",
       " 'model': {'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': True,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'use_attention': False,\n",
       "  'attention_num_transformer_units': 1,\n",
       "  'attention_dim': 64,\n",
       "  'attention_num_heads': 1,\n",
       "  'attention_head_dim': 32,\n",
       "  'attention_memory_inference': 50,\n",
       "  'attention_memory_training': 50,\n",
       "  'attention_position_wise_mlp_dim': 32,\n",
       "  'attention_init_gru_gate_bias': 2.0,\n",
       "  'num_framestacks': 'auto',\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1,\n",
       "  'framestack': True},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {},\n",
       " 'env': ray.rllib.contrib.bandits.envs.discrete.WheelBanditEnv,\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 0.0001,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'torch',\n",
       " 'eager_tracing': False,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'ray.rllib.contrib.bandits.exploration.ThompsonSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " '_use_trajectory_view_api': True,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 100,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent',\n",
       "  'count_steps_by': 'env_steps'},\n",
       " 'logger_config': None,\n",
       " 'replay_sequence_length': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Ray..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-22 13:30:50,283\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.156',\n",
       " 'raylet_ip_address': '192.168.1.156',\n",
       " 'redis_address': '192.168.1.156:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-05-22_13-30-49_767763_30692/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-05-22_13-30-49_767763_30692/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-05-22_13-30-49_767763_30692',\n",
       " 'metrics_export_port': 61234,\n",
       " 'node_id': '7d1f994385e9e0c6c9bcfd7988132668597230eedf8b7da2fd080ebd'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray.get_gpu_ids(): []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'CUDA_VISIBLE_DEVICES'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7e03a3084ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ray.get_gpu_ids(): {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CUDA_VISIBLE_DEVICES'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"ray.get_gpu_ids(): {}\".format(ray.get_gpu_ids()))\n",
    "print(\"CUDA_VISIBLE_DEVICES: {}\".format(os.environ[\"CUDA_VISIBLE_DEVICES\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 3.7/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/36.52 GiB heap, 0.0/12.6 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/paco/ray_results/LinTS_2021-05-22_13-31-00<br>Number of trials: 2/2 (2 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-22 13:31:05,144\tINFO tune.py:450 -- Total run time: 4.60 seconds (4.29 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "analysis = ray.tune.run(\n",
    "    LinTSTrainer,\n",
    "    config=TS_CONFIG,\n",
    "    stop={\"training_iteration\": training_iterations},\n",
    "    num_samples=2,\n",
    "    checkpoint_at_end=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long did it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4.29 seconds,    0.07 minutes\n"
     ]
    }
   ],
   "source": [
    "stats = analysis.stats()\n",
    "secs = stats[\"timestamp\"] - stats[\"start_time\"]\n",
    "print(f'{secs:7.2f} seconds, {secs/60.0:7.2f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze cumulative regrets of the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>info/num_steps_trained</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2012.934657</td>\n",
       "      <td>2111.142077</td>\n",
       "      <td>1914.727236</td>\n",
       "      <td>138.886266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3757.799133</td>\n",
       "      <td>3928.316339</td>\n",
       "      <td>3587.281926</td>\n",
       "      <td>241.147747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5575.537827</td>\n",
       "      <td>5647.915735</td>\n",
       "      <td>5503.159919</td>\n",
       "      <td>102.357819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>7393.347944</td>\n",
       "      <td>7709.368085</td>\n",
       "      <td>7077.327804</td>\n",
       "      <td>446.919969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>8941.911893</td>\n",
       "      <td>9282.711536</td>\n",
       "      <td>8601.112250</td>\n",
       "      <td>481.963478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>10343.186242</td>\n",
       "      <td>11002.852180</td>\n",
       "      <td>9683.520304</td>\n",
       "      <td>932.908516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>11646.593932</td>\n",
       "      <td>12429.244236</td>\n",
       "      <td>10863.943628</td>\n",
       "      <td>1106.834674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>12582.377369</td>\n",
       "      <td>13218.902941</td>\n",
       "      <td>11945.851797</td>\n",
       "      <td>900.183097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>13714.240652</td>\n",
       "      <td>14448.649999</td>\n",
       "      <td>12979.831306</td>\n",
       "      <td>1038.611658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>14748.141884</td>\n",
       "      <td>15580.963798</td>\n",
       "      <td>13915.319970</td>\n",
       "      <td>1177.788046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>15756.116558</td>\n",
       "      <td>16564.393292</td>\n",
       "      <td>14947.839823</td>\n",
       "      <td>1143.075920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>16447.491977</td>\n",
       "      <td>17843.205263</td>\n",
       "      <td>15051.778690</td>\n",
       "      <td>1973.836659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>17064.344050</td>\n",
       "      <td>19023.775979</td>\n",
       "      <td>15104.912121</td>\n",
       "      <td>2771.055209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>17632.711239</td>\n",
       "      <td>20106.250043</td>\n",
       "      <td>15159.172435</td>\n",
       "      <td>3498.112124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>18005.198438</td>\n",
       "      <td>20699.775330</td>\n",
       "      <td>15310.621545</td>\n",
       "      <td>3810.707187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>18498.770549</td>\n",
       "      <td>21585.509549</td>\n",
       "      <td>15412.031550</td>\n",
       "      <td>4365.308157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>19018.650724</td>\n",
       "      <td>22570.372654</td>\n",
       "      <td>15466.928795</td>\n",
       "      <td>5022.893323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>19561.807507</td>\n",
       "      <td>23652.272738</td>\n",
       "      <td>15471.342275</td>\n",
       "      <td>5784.791407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>20228.350448</td>\n",
       "      <td>24882.303073</td>\n",
       "      <td>15574.397823</td>\n",
       "      <td>6581.682920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>20772.551659</td>\n",
       "      <td>25916.246142</td>\n",
       "      <td>15628.857175</td>\n",
       "      <td>7274.282499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean           max           min          std\n",
       "info/num_steps_trained                                                       \n",
       "100                      2012.934657   2111.142077   1914.727236   138.886266\n",
       "200                      3757.799133   3928.316339   3587.281926   241.147747\n",
       "300                      5575.537827   5647.915735   5503.159919   102.357819\n",
       "400                      7393.347944   7709.368085   7077.327804   446.919969\n",
       "500                      8941.911893   9282.711536   8601.112250   481.963478\n",
       "600                     10343.186242  11002.852180   9683.520304   932.908516\n",
       "700                     11646.593932  12429.244236  10863.943628  1106.834674\n",
       "800                     12582.377369  13218.902941  11945.851797   900.183097\n",
       "900                     13714.240652  14448.649999  12979.831306  1038.611658\n",
       "1000                    14748.141884  15580.963798  13915.319970  1177.788046\n",
       "1100                    15756.116558  16564.393292  14947.839823  1143.075920\n",
       "1200                    16447.491977  17843.205263  15051.778690  1973.836659\n",
       "1300                    17064.344050  19023.775979  15104.912121  2771.055209\n",
       "1400                    17632.711239  20106.250043  15159.172435  3498.112124\n",
       "1500                    18005.198438  20699.775330  15310.621545  3810.707187\n",
       "1600                    18498.770549  21585.509549  15412.031550  4365.308157\n",
       "1700                    19018.650724  22570.372654  15466.928795  5022.893323\n",
       "1800                    19561.807507  23652.272738  15471.342275  5784.791407\n",
       "1900                    20228.350448  24882.303073  15574.397823  6581.682920\n",
       "2000                    20772.551659  25916.246142  15628.857175  7274.282499"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for key, df_trial in analysis.trial_dataframes.items():\n",
    "    df = df.append(df_trial, ignore_index=True)\n",
    "\n",
    "regrets = df \\\n",
    "    .groupby(\"info/num_steps_trained\")[\"info/learner/default_policy/cumulative_regret\"] \\\n",
    "    .aggregate([\"mean\", \"max\", \"min\", \"std\"])\n",
    "\n",
    "regrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f37303d8820>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regrets.plot(y=\"mean\", title=\"Cumulative Regrets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, here is an [image](../../images/rllib/LinTS-Cumulative-Regret-05.png) from a previous run. How similar is your graph? We have observed a great deal of variability from one run to the next, more than we have seen with _LinUCB_. This suggests that extra caution is required when using _LinTS_ to ensure that good results are achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you can restore a trainer from a checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-22 13:31:17,001\tINFO trainer.py:641 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #2 'vec' in call to _th_mv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f000a91fd7d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinTSTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTS_CONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         def _init(self, config: TrainerConfigDict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mlogger_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_logger_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, logger_creator)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0msetup_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msetup_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mSETUP_TIME_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mget_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;31m# Evaluation setup.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, config, env_creator)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# Creating all workers (excluding evaluation workers).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             self.workers = self._make_workers(\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0menv_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mvalidate_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36m_make_workers\u001b[0;34m(self, env_creator, validate_env, policy_class, config, num_workers)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mWorkerSet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mWorkerSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \"\"\"\n\u001b[0;32m--> 725\u001b[0;31m         return WorkerSet(\n\u001b[0m\u001b[1;32m    726\u001b[0m             \u001b[0menv_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mvalidate_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_creator, validate_env, policy_class, trainer_config, num_workers, logdir, _setup)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Always create a local worker.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             self._local_worker = self._make_worker(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRolloutWorker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0menv_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\u001b[0m in \u001b[0;36m_make_worker\u001b[0;34m(self, cls, env_creator, validate_env, policy_cls, worker_index, num_workers, config, spaces)\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \"extra_python_environs_for_worker\", None)\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         worker = cls(\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0menv_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mvalidate_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_creator, validate_env, policy_spec, policy_mapping_fn, policies_to_train, tf_session_creator, rollout_fragment_length, count_steps_by, batch_mode, episode_horizon, preprocessor_pref, sample_async, compress_observations, num_envs, observation_fn, observation_filter, clip_rewards, clip_actions, env_config, model_config, policy_config, worker_index, num_workers, monitor_path, log_dir, log_level, callbacks, input_creator, input_evaluation, output_creator, remote_worker_envs, remote_env_batch_wait_ms, soft_horizon, no_done_at_end, seed, extra_python_environs, fake_sampler, spaces, _use_trajectory_view_api, policy)\u001b[0m\n\u001b[1;32m    477\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_policy_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             self.policy_map, self.preprocessors = self._build_policy_map(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 policy_dict, policy_config)\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\u001b[0m in \u001b[0;36m_build_policy_map\u001b[0;34m(self, policy_dict, policy_config)\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# non-tf.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                 \u001b[0mpolicy_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_template.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obs_space, action_space, config)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;31m# Perform test runs through postprocessing- and loss functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             self._initialize_loss_from_dummy_batch(\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0mauto_remove_unneeded_view_reqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mstats_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstats_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/policy/policy.py\u001b[0m in \u001b[0;36m_initialize_loss_from_dummy_batch\u001b[0;34m(self, auto_remove_unneeded_view_reqs, stats_fn)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dummy_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_outs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_actions_from_input_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;31m# Add all extra action outputs to view reqirements (these may be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# filtered out later again, if not needed for postprocessing or loss).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy.py\u001b[0m in \u001b[0;36mcompute_actions_from_input_dict\u001b[0;34m(self, input_dict, explore, timestep, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstate_batches\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             return self._compute_action_helper(input_dict, state_batches,\n\u001b[0m\u001b[1;32m    208\u001b[0m                                                seq_lens, explore, timestep)\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/utils/threading.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             raise AttributeError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy.py\u001b[0m in \u001b[0;36m_compute_action_helper\u001b[0;34m(self, input_dict, state_batches, seq_lens, explore, timestep)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0mdist_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 dist_inputs, state_out = self.model(input_dict, state_batches,\n\u001b[0m\u001b[1;32m    250\u001b[0m                                                     seq_lens)\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/models/modelv2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mrestored\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs_flat\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         if ((not isinstance(res, list) and not isinstance(res, tuple))\n\u001b[1;32m    213\u001b[0m                 or len(res) != 2):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/contrib/bandits/models/linear_regression.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         scores = super(DiscreteLinearModelThompsonSampling, self).predict(\n\u001b[0m\u001b[1;32m    165\u001b[0m             x, sample_theta=True, use_ucb=False)\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/contrib/bandits/models/linear_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, sample_theta, use_ucb)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cur_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         scores = torch.stack(\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_theta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             dim=-1)\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cur_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/contrib/bandits/models/linear_regression.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cur_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         scores = torch.stack(\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_theta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             dim=-1)\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cur_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/contrib/bandits/models/linear_regression.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sample_theta)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_theta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_theta\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #2 'vec' in call to _th_mv"
     ]
    }
   ],
   "source": [
    "trial = analysis.trials[0]\n",
    "trainer = LinTSTrainer(config=TS_CONFIG)\n",
    "trainer.restore(trial.checkpoint.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model to plot arm weights distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d85b15eb4da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcovs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "model = trainer.get_policy().model\n",
    "means = [model.arms[i].theta.numpy() for i in range(5)]\n",
    "covs = [model.arms[i].covariance.numpy() for i in range(5)]\n",
    "model, means, covs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the weight distributions for the different arms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors  = [\"blue\", \"black\", \"green\", \"red\", \"yellow\"]\n",
    "labels  = [\"arm{}\".format(i) for i in range(5)]\n",
    "\n",
    "for i in range(0, 5):\n",
    "    x, y = np.random.multivariate_normal(means[i] / 30, covs[i], 5000).T\n",
    "    plt.scatter(x, y, color=colors[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an [image](../../images/rllib/LinTS-Weight-Distribution-of-Arms-05.png) from a previous run. How similar is your graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Experiment with different $\\delta$ values, for example 0.7 and 0.9. What do the cumulative regret and weights graphs look like? \n",
    "\n",
    "You can set the $\\delta$ value like this:\n",
    "\n",
    "```python\n",
    "TS_CONFIG[\"delta\"] = 0.7\n",
    "```\n",
    "\n",
    "See the [solutions notebook](solutions/Multi-Armed-Bandits-Solutions.ipynb) for discussion of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
