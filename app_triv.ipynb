{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JD0Eu7JWdVqY"
   },
   "source": [
    "# RLlib Sample Application: trivial-v0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses [RLlib](https://ray.readthedocs.io/en/latest/rllib.html) to trains a policy with the `trivial-v0` environment:\n",
    "\n",
    "  - <https://github.com/DerwenAI/gym_trivial> \n",
    "\n",
    "This example is designed to illustrate how to build a minimal `gym` environment which implements all of the features required. Effectively, it simulates the operation of an `AND` gate in TTL which is trivial.\n",
    "\n",
    "---\n",
    "\n",
    "First, make sure that Ray and RLlib are installed…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ray[rllib]\n",
    "!pip install ray[debug]\n",
    "!pip install ray[tune]\n",
    "!pip install pandas\n",
    "!pip install requests\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then start Ray…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a successful launch, the last log output line should read `View the Ray dashboard at localhost:8265`\n",
    "\n",
    "Open <http://localhost:8265/> in another tab to view the Ray dashboard as the example runs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll train an RLlib policy with the `trivial-v0` environment <https://github.com/DerwenAI/gym_trivial>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+git://github.com/DerwenAI/gym_trivial.git#egg=pkg&subdirectory=gym-trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_trivial.envs.trivial_env import Trivial\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "register_env(\"trivial-v0\", lambda config: Trivial())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, training runs for only `1` iteration. Increase the `n_iter` setting if you want to see the resulting rewards improve.\n",
    "Also note that *checkpoints* get saved after each iteration into the `/tmp/ppo/triv` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_ENV = \"trivial-v0\"\n",
    "N_ITER = 1\n",
    "\n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"log_level\"] = \"WARN\"\n",
    "\n",
    "reward_history = []\n",
    "\n",
    "agent = ppo.PPOTrainer(config, env=SELECT_ENV)\n",
    "\n",
    "for _ in range(N_ITER):\n",
    "    result = agent.train()\n",
    "    print(result)\n",
    "\n",
    "    max_reward = result[\"episode_reward_max\"]\n",
    "    reward_history.append(max_reward)\n",
    "\n",
    "    file_name = agent.save(\"/tmp/ppo/triv\")\n",
    "    print(f\"\\n{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reward_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gp1LgeCJjGLk"
   },
   "source": [
    "Do the episode rewards increase after multiple iterations?\n",
    "That shows how the policy is improving.\n",
    "\n",
    "Also, print out the policy and model to see the results of training in detail…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "policy = agent.get_policy()\n",
    "model = policy.model\n",
    "\n",
    "pprint.pprint(model.variables())\n",
    "pprint.pprint(model.value_function())\n",
    "\n",
    "print(model.base_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use the [`rollout` script](https://ray.readthedocs.io/en/latest/rllib-training.html#evaluating-trained-policies) to evaluate the trained policy.\n",
    "\n",
    "This visualizes the \"trivial\" agent operating within the simulation: setting either of two inputs until both are set.\n",
    "\n",
    "**(NB: the `rollout` CLI script will not work with custom env)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rllib rollout \\\n",
    "    /tmp/ppo/triv/checkpoint_2/checkpoint-2 \\\n",
    "    --config \"{\\\"env\\\": \\\"trivial-v0\\\"}\" --run PPO \\\n",
    "    --steps 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tI9vJ1vU6Mj1"
   },
   "source": [
    "The rollout uses the second saved checkpoint, evaluated through `2000` steps.\n",
    "Modify the path to view other checkpoints.\n",
    "\n",
    "---\n",
    "\n",
    "Finally, launch [TensorBoard](https://ray.readthedocs.io/en/latest/rllib-training.html#getting-started) then follow the instructions (copy/paste the URL it generates) to visualize key metrics from training with RLlib…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=~/ray_results/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of rllib_ppo_dqn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
