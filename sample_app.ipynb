{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JD0Eu7JWdVqY"
   },
   "source": [
    "# RLlib Sample Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure that Ray and RLlib are installed…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[rllib] in /opt/anaconda3/lib/python3.7/site-packages (0.8.2)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (3.6.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (1.18.1)\n",
      "Requirement already satisfied: jsonschema in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (3.0.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (7.0)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (4.1.1)\n",
      "Requirement already satisfied: colorama in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (0.4.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (3.0.12)\n",
      "Requirement already satisfied: funcsigs in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (1.0.2)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (5.1.2)\n",
      "Requirement already satisfied: six>=1.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (1.12.0)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (0.3.3)\n",
      "Requirement already satisfied: grpcio in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (1.26.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (19.2)\n",
      "Requirement already satisfied: redis>=3.3.2 in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (3.3.11)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (3.11.2)\n",
      "Requirement already satisfied: google in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (2.0.3)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (1.2.2)\n",
      "Requirement already satisfied: tabulate; extra == \"rllib\" in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (0.8.6)\n",
      "Requirement already satisfied: lz4; extra == \"rllib\" in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (3.0.2)\n",
      "Requirement already satisfied: tensorboardX; extra == \"rllib\" in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (1.9)\n",
      "Requirement already satisfied: scipy; extra == \"rllib\" in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (1.4.1)\n",
      "Requirement already satisfied: opencv-python-headless; extra == \"rllib\" in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (4.1.2.30)\n",
      "Requirement already satisfied: gym[atari]; extra == \"rllib\" in /opt/anaconda3/lib/python3.7/site-packages (from ray[rllib]) (0.15.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[rllib]) (19.2.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[rllib]) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[rllib]) (1.4.2)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[rllib]) (4.7.5)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[rllib]) (3.0.4)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[rllib]) (0.15.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[rllib]) (45.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[rllib]) (1.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[rllib]) (7.2.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[rllib]) (1.8.0)\n",
      "Requirement already satisfied: pluggy>=0.7 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[rllib]) (0.13.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from packaging->ray[rllib]) (2.3.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.7/site-packages (from google->ray[rllib]) (4.8.0)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.7/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (4.1.2.30)\n",
      "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /opt/anaconda3/lib/python3.7/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (1.3.2)\n",
      "Requirement already satisfied: Pillow; extra == \"atari\" in /opt/anaconda3/lib/python3.7/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (6.2.0)\n",
      "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /opt/anaconda3/lib/python3.7/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (0.2.6)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->ray[rllib]) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from pluggy>=0.7->pytest->ray[rllib]) (0.23)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /opt/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->google->ray[rllib]) (1.9.3)\n",
      "Requirement already satisfied: future in /opt/anaconda3/lib/python3.7/site-packages (from pyglet<=1.3.2,>=1.2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.17.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pluggy>=0.7->pytest->ray[rllib]) (0.6.0)\n",
      "Requirement already satisfied: ray[debug] in /opt/anaconda3/lib/python3.7/site-packages (0.8.2)\n",
      "Requirement already satisfied: grpcio in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (1.26.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (3.0.12)\n",
      "Requirement already satisfied: six>=1.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (1.12.0)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (4.1.1)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (0.3.3)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (3.6.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (7.0)\n",
      "Requirement already satisfied: jsonschema in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (3.0.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (3.11.2)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (19.2)\n",
      "Requirement already satisfied: google in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (2.0.3)\n",
      "Requirement already satisfied: redis>=3.3.2 in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (3.3.11)\n",
      "Requirement already satisfied: funcsigs in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (1.0.2)\n",
      "Requirement already satisfied: colorama in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (0.4.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (1.2.2)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (5.1.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/anaconda3/lib/python3.7/site-packages (from ray[debug]) (1.18.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[debug]) (1.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[debug]) (19.2.0)\n",
      "Requirement already satisfied: pluggy>=0.7 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[debug]) (0.13.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[debug]) (7.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[debug]) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[debug]) (45.2.0)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[debug]) (4.7.5)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[debug]) (3.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[debug]) (1.4.2)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[debug]) (3.0.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[debug]) (0.15.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from packaging->ray[debug]) (2.3.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.7/site-packages (from google->ray[debug]) (4.8.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from pluggy>=0.7->pytest->ray[debug]) (0.23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->ray[debug]) (2.8)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /opt/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->google->ray[debug]) (1.9.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pluggy>=0.7->pytest->ray[debug]) (0.6.0)\n",
      "Requirement already satisfied: ray[tune] in /opt/anaconda3/lib/python3.7/site-packages (0.8.2)\n",
      "Requirement already satisfied: six>=1.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.12.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (19.2)\n",
      "Requirement already satisfied: redis>=3.3.2 in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.3.11)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.2.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (7.0)\n",
      "Requirement already satisfied: google in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (2.0.3)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.6.2)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (5.1.2)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.18.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.11.2)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (0.3.3)\n",
      "Requirement already satisfied: grpcio in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.26.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.0.12)\n",
      "Requirement already satisfied: colorama in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (0.4.1)\n",
      "Requirement already satisfied: jsonschema in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.0.2)\n",
      "Requirement already satisfied: funcsigs in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.0.2)\n",
      "Requirement already satisfied: tensorboardX; extra == \"tune\" in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.9)\n",
      "Requirement already satisfied: tabulate; extra == \"tune\" in /opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (0.8.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from packaging->ray[tune]) (2.3.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.7/site-packages (from google->ray[tune]) (4.8.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[tune]) (3.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[tune]) (1.4.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[tune]) (19.2.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[tune]) (3.0.1)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /opt/anaconda3/lib/python3.7/site-packages (from aiohttp->ray[tune]) (4.7.5)\n",
      "Requirement already satisfied: pluggy>=0.7 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[tune]) (0.13.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[tune]) (1.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[tune]) (7.2.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[tune]) (1.8.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from pytest->ray[tune]) (45.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[tune]) (0.15.4)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /opt/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->google->ray[tune]) (1.9.3)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->ray[tune]) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from pluggy>=0.7->pytest->ray[tune]) (0.23)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pluggy>=0.7->pytest->ray[tune]) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ray[rllib]\n",
    "!pip install ray[debug]\n",
    "!pip install ray[tune]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start Ray…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 18:11:05,442\tINFO resource_spec.py:212 -- Starting Ray with 2.39 GiB memory available for workers and up to 1.2 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-03-21 18:11:05,866\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.65',\n",
       " 'redis_address': '192.168.1.65:50527',\n",
       " 'object_store_address': '/tmp/ray/session_2020-03-21_18-11-05_431051_2939/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-03-21_18-11-05_431051_2939/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-03-21_18-11-05_431051_2939'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a successful launch, there should be a log output line that reads something to the effect of `View the Ray dashboard at localhost:8265` in which case open another browser tab for the Ray dashboard at <http://localhost:8265/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll train an RLlib policy with the `CartPole-v0` environment, which is a relatively simple and quick example. For more details about this problem, see the tutorial [*Cartpole - Introduction to Reinforcement Learning (DQN - Deep Q-Learning)*](https://towardsdatascience.com/cartpole-introduction-to-reinforcement-learning-ed0eb5b58288) by [Greg Surma](https://twitter.com/GSurma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 18:11:13,165\tINFO trainer.py:420 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2020-03-21 18:11:13,211\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\n",
      "2020-03-21 18:11:17,172\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2998)\u001b[0m /opt/anaconda3/lib/python3.7/site-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\u001b[2m\u001b[36m(pid=2998)\u001b[0m   obj = yaml.load(type_)\n",
      "\u001b[2m\u001b[36m(pid=2997)\u001b[0m /opt/anaconda3/lib/python3.7/site-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\u001b[2m\u001b[36m(pid=2997)\u001b[0m   obj = yaml.load(type_)\n",
      "{'episode_reward_max': 75.0, 'episode_reward_min': 9.0, 'episode_reward_mean': 21.0, 'episode_len_mean': 21.0, 'episodes_this_iter': 187, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [11.0, 23.0, 18.0, 31.0, 48.0, 21.0, 20.0, 27.0, 13.0, 15.0, 36.0, 26.0, 12.0, 13.0, 23.0, 15.0, 49.0, 24.0, 32.0, 38.0, 16.0, 13.0, 12.0, 24.0, 9.0, 14.0, 14.0, 46.0, 20.0, 44.0, 15.0, 15.0, 27.0, 24.0, 20.0, 14.0, 19.0, 14.0, 34.0, 15.0, 30.0, 19.0, 13.0, 25.0, 27.0, 22.0, 27.0, 31.0, 16.0, 16.0, 75.0, 24.0, 35.0, 21.0, 11.0, 14.0, 25.0, 35.0, 13.0, 42.0, 15.0, 17.0, 19.0, 15.0, 30.0, 16.0, 12.0, 10.0, 22.0, 13.0, 12.0, 16.0, 17.0, 35.0, 11.0, 35.0, 27.0, 15.0, 29.0, 13.0, 12.0, 11.0, 15.0, 18.0, 11.0, 19.0, 10.0, 24.0, 42.0, 26.0, 19.0, 31.0, 19.0, 17.0, 13.0, 17.0, 12.0, 12.0, 12.0, 11.0, 14.0, 23.0, 13.0, 16.0, 12.0, 26.0, 12.0, 26.0, 63.0, 42.0, 18.0, 20.0, 17.0, 20.0, 14.0, 31.0, 16.0, 18.0, 18.0, 11.0, 17.0, 25.0, 17.0, 26.0, 26.0, 16.0, 20.0, 23.0, 20.0, 19.0, 10.0, 27.0, 10.0, 10.0, 16.0, 10.0, 20.0, 28.0, 25.0, 14.0, 18.0, 41.0, 24.0, 14.0, 10.0, 27.0, 38.0, 17.0, 10.0, 17.0, 42.0, 18.0, 18.0, 11.0, 15.0, 16.0, 18.0, 29.0, 14.0, 23.0, 15.0, 13.0, 12.0, 14.0, 18.0, 9.0, 17.0, 25.0, 31.0, 24.0, 23.0, 11.0, 15.0, 21.0, 21.0, 19.0, 21.0, 17.0, 26.0, 42.0, 19.0, 31.0, 45.0, 10.0, 11.0, 20.0, 13.0], 'episode_lengths': [11, 23, 18, 31, 48, 21, 20, 27, 13, 15, 36, 26, 12, 13, 23, 15, 49, 24, 32, 38, 16, 13, 12, 24, 9, 14, 14, 46, 20, 44, 15, 15, 27, 24, 20, 14, 19, 14, 34, 15, 30, 19, 13, 25, 27, 22, 27, 31, 16, 16, 75, 24, 35, 21, 11, 14, 25, 35, 13, 42, 15, 17, 19, 15, 30, 16, 12, 10, 22, 13, 12, 16, 17, 35, 11, 35, 27, 15, 29, 13, 12, 11, 15, 18, 11, 19, 10, 24, 42, 26, 19, 31, 19, 17, 13, 17, 12, 12, 12, 11, 14, 23, 13, 16, 12, 26, 12, 26, 63, 42, 18, 20, 17, 20, 14, 31, 16, 18, 18, 11, 17, 25, 17, 26, 26, 16, 20, 23, 20, 19, 10, 27, 10, 10, 16, 10, 20, 28, 25, 14, 18, 41, 24, 14, 10, 27, 38, 17, 10, 17, 42, 18, 18, 11, 15, 16, 18, 29, 14, 23, 15, 13, 12, 14, 18, 9, 17, 25, 31, 24, 23, 11, 15, 21, 21, 19, 21, 17, 26, 42, 19, 31, 45, 10, 11, 20, 13]}, 'sampler_perf': {'mean_env_wait_ms': 0.04786613530783665, 'mean_processing_ms': 0.13463112830761462, 'mean_inference_ms': 0.6158174753788659}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 3968, 'num_steps_sampled': 4000, 'sample_time_ms': 3174.275, 'load_time_ms': 59.988, 'grad_time_ms': 2452.683, 'update_time_ms': 642.372, 'learner': {'default_policy': {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 82.55155, 'policy_loss': -0.04548664, 'vf_loss': 82.59072, 'vf_explained_var': 0.05240275, 'kl': 0.031586733, 'entropy': 0.6622803, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 4000, 'episodes_total': 187, 'training_iteration': 1, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-23', 'timestamp': 1584839483, 'time_this_iter_s': 6.378158092498779, 'time_total_s': 6.378158092498779, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 6.378158092498779, 'timesteps_since_restore': 4000, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 61.77, 'ram_util_percent': 59.67}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_1/checkpoint-1\n",
      "{'episode_reward_max': 145.0, 'episode_reward_min': 9.0, 'episode_reward_mean': 44.46, 'episode_len_mean': 44.46, 'episodes_this_iter': 78, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [31.0, 30.0, 20.0, 17.0, 101.0, 22.0, 14.0, 79.0, 81.0, 38.0, 139.0, 34.0, 70.0, 39.0, 30.0, 22.0, 19.0, 25.0, 59.0, 54.0, 66.0, 37.0, 33.0, 72.0, 78.0, 11.0, 91.0, 102.0, 75.0, 41.0, 100.0, 16.0, 23.0, 52.0, 35.0, 37.0, 41.0, 77.0, 66.0, 108.0, 76.0, 55.0, 37.0, 67.0, 75.0, 49.0, 48.0, 22.0, 18.0, 82.0, 145.0, 23.0, 17.0, 25.0, 144.0, 15.0, 85.0, 18.0, 62.0, 65.0, 21.0, 51.0, 73.0, 42.0, 65.0, 27.0, 12.0, 22.0, 34.0, 34.0, 82.0, 87.0, 16.0, 23.0, 27.0, 59.0, 60.0, 27.0, 9.0, 17.0, 25.0, 31.0, 24.0, 23.0, 11.0, 15.0, 21.0, 21.0, 19.0, 21.0, 17.0, 26.0, 42.0, 19.0, 31.0, 45.0, 10.0, 11.0, 20.0, 13.0], 'episode_lengths': [31, 30, 20, 17, 101, 22, 14, 79, 81, 38, 139, 34, 70, 39, 30, 22, 19, 25, 59, 54, 66, 37, 33, 72, 78, 11, 91, 102, 75, 41, 100, 16, 23, 52, 35, 37, 41, 77, 66, 108, 76, 55, 37, 67, 75, 49, 48, 22, 18, 82, 145, 23, 17, 25, 144, 15, 85, 18, 62, 65, 21, 51, 73, 42, 65, 27, 12, 22, 34, 34, 82, 87, 16, 23, 27, 59, 60, 27, 9, 17, 25, 31, 24, 23, 11, 15, 21, 21, 19, 21, 17, 26, 42, 19, 31, 45, 10, 11, 20, 13]}, 'sampler_perf': {'mean_env_wait_ms': 0.05173081751573825, 'mean_processing_ms': 0.13693180924043113, 'mean_inference_ms': 0.6509317584754382}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 7936, 'num_steps_sampled': 8000, 'sample_time_ms': 2504.909, 'load_time_ms': 31.004, 'grad_time_ms': 2360.359, 'update_time_ms': 322.875, 'learner': {'default_policy': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 388.6111, 'policy_loss': -0.03004014, 'vf_loss': 388.6353, 'vf_explained_var': 0.10915986, 'kl': 0.019172587, 'entropy': 0.60596645, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 8000, 'episodes_total': 265, 'training_iteration': 2, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-27', 'timestamp': 1584839487, 'time_this_iter_s': 4.112191915512085, 'time_total_s': 10.490350008010864, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 10.490350008010864, 'timesteps_since_restore': 8000, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 75.61666666666667, 'ram_util_percent': 59.85}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_2/checkpoint-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': 200.0, 'episode_reward_min': 11.0, 'episode_reward_mean': 72.05, 'episode_len_mean': 72.05, 'episodes_this_iter': 37, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [121.0, 23.0, 88.0, 163.0, 68.0, 115.0, 80.0, 200.0, 53.0, 32.0, 114.0, 116.0, 169.0, 110.0, 146.0, 109.0, 67.0, 200.0, 123.0, 99.0, 99.0, 84.0, 110.0, 133.0, 47.0, 101.0, 116.0, 106.0, 167.0, 200.0, 29.0, 59.0, 83.0, 34.0, 62.0, 200.0, 149.0, 22.0, 19.0, 25.0, 59.0, 54.0, 66.0, 37.0, 33.0, 72.0, 78.0, 11.0, 91.0, 102.0, 75.0, 41.0, 100.0, 16.0, 23.0, 52.0, 35.0, 37.0, 41.0, 77.0, 66.0, 108.0, 76.0, 55.0, 37.0, 67.0, 75.0, 49.0, 48.0, 22.0, 18.0, 82.0, 145.0, 23.0, 17.0, 25.0, 144.0, 15.0, 85.0, 18.0, 62.0, 65.0, 21.0, 51.0, 73.0, 42.0, 65.0, 27.0, 12.0, 22.0, 34.0, 34.0, 82.0, 87.0, 16.0, 23.0, 27.0, 59.0, 60.0, 27.0], 'episode_lengths': [121, 23, 88, 163, 68, 115, 80, 200, 53, 32, 114, 116, 169, 110, 146, 109, 67, 200, 123, 99, 99, 84, 110, 133, 47, 101, 116, 106, 167, 200, 29, 59, 83, 34, 62, 200, 149, 22, 19, 25, 59, 54, 66, 37, 33, 72, 78, 11, 91, 102, 75, 41, 100, 16, 23, 52, 35, 37, 41, 77, 66, 108, 76, 55, 37, 67, 75, 49, 48, 22, 18, 82, 145, 23, 17, 25, 144, 15, 85, 18, 62, 65, 21, 51, 73, 42, 65, 27, 12, 22, 34, 34, 82, 87, 16, 23, 27, 59, 60, 27]}, 'sampler_perf': {'mean_env_wait_ms': 0.053399163587821985, 'mean_processing_ms': 0.13743905406382345, 'mean_inference_ms': 0.6649957393500242}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 11904, 'num_steps_sampled': 12000, 'sample_time_ms': 2275.998, 'load_time_ms': 21.036, 'grad_time_ms': 2319.725, 'update_time_ms': 216.389, 'learner': {'default_policy': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 399.92737, 'policy_loss': -0.018100126, 'vf_loss': 399.94193, 'vf_explained_var': 0.18387239, 'kl': 0.011822484, 'entropy': 0.5651478, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 12000, 'episodes_total': 302, 'training_iteration': 3, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-31', 'timestamp': 1584839491, 'time_this_iter_s': 4.066025972366333, 'time_total_s': 14.556375980377197, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 14.556375980377197, 'timesteps_since_restore': 12000, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 73.96, 'ram_util_percent': 59.1}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_3/checkpoint-3\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 12.0, 'episode_reward_mean': 100.36, 'episode_len_mean': 100.36, 'episodes_this_iter': 24, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 183.0, 200.0, 200.0, 200.0, 93.0, 55.0, 80.0, 142.0, 200.0, 200.0, 200.0, 97.0, 200.0, 199.0, 14.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 108.0, 76.0, 55.0, 37.0, 67.0, 75.0, 49.0, 48.0, 22.0, 18.0, 82.0, 145.0, 23.0, 17.0, 25.0, 144.0, 15.0, 85.0, 18.0, 62.0, 65.0, 21.0, 51.0, 73.0, 42.0, 65.0, 27.0, 12.0, 22.0, 34.0, 34.0, 82.0, 87.0, 16.0, 23.0, 27.0, 59.0, 60.0, 27.0, 121.0, 23.0, 88.0, 163.0, 68.0, 115.0, 80.0, 200.0, 53.0, 32.0, 114.0, 116.0, 169.0, 110.0, 146.0, 109.0, 67.0, 200.0, 123.0, 99.0, 99.0, 84.0, 110.0, 133.0, 47.0, 101.0, 116.0, 106.0, 167.0, 200.0, 29.0, 59.0, 83.0, 34.0, 62.0, 200.0, 149.0], 'episode_lengths': [200, 200, 200, 183, 200, 200, 200, 93, 55, 80, 142, 200, 200, 200, 97, 200, 199, 14, 200, 200, 200, 200, 200, 200, 108, 76, 55, 37, 67, 75, 49, 48, 22, 18, 82, 145, 23, 17, 25, 144, 15, 85, 18, 62, 65, 21, 51, 73, 42, 65, 27, 12, 22, 34, 34, 82, 87, 16, 23, 27, 59, 60, 27, 121, 23, 88, 163, 68, 115, 80, 200, 53, 32, 114, 116, 169, 110, 146, 109, 67, 200, 123, 99, 99, 84, 110, 133, 47, 101, 116, 106, 167, 200, 29, 59, 83, 34, 62, 200, 149]}, 'sampler_perf': {'mean_env_wait_ms': 0.05386685159718919, 'mean_processing_ms': 0.13723949220143253, 'mean_inference_ms': 0.6695713053013702}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 15872, 'num_steps_sampled': 16000, 'sample_time_ms': 2160.315, 'load_time_ms': 16.069, 'grad_time_ms': 2269.345, 'update_time_ms': 163.45, 'learner': {'default_policy': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 606.07367, 'policy_loss': -0.0040238122, 'vf_loss': 606.0761, 'vf_explained_var': 0.19948976, 'kl': 0.005175018, 'entropy': 0.5427736, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 16000, 'episodes_total': 326, 'training_iteration': 4, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-35', 'timestamp': 1584839495, 'time_this_iter_s': 3.941624164581299, 'time_total_s': 18.498000144958496, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 18.498000144958496, 'timesteps_since_restore': 16000, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 73.95, 'ram_util_percent': 58.93333333333333}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_4/checkpoint-4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': 200.0, 'episode_reward_min': 12.0, 'episode_reward_mean': 126.64, 'episode_len_mean': 126.64, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 146.0, 200.0, 200.0, 72.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 65.0, 21.0, 51.0, 73.0, 42.0, 65.0, 27.0, 12.0, 22.0, 34.0, 34.0, 82.0, 87.0, 16.0, 23.0, 27.0, 59.0, 60.0, 27.0, 121.0, 23.0, 88.0, 163.0, 68.0, 115.0, 80.0, 200.0, 53.0, 32.0, 114.0, 116.0, 169.0, 110.0, 146.0, 109.0, 67.0, 200.0, 123.0, 99.0, 99.0, 84.0, 110.0, 133.0, 47.0, 101.0, 116.0, 106.0, 167.0, 200.0, 29.0, 59.0, 83.0, 34.0, 62.0, 200.0, 149.0, 200.0, 200.0, 200.0, 183.0, 200.0, 200.0, 200.0, 93.0, 55.0, 80.0, 142.0, 200.0, 200.0, 200.0, 97.0, 200.0, 199.0, 14.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0], 'episode_lengths': [200, 200, 200, 200, 200, 190, 200, 146, 200, 200, 72, 200, 200, 200, 200, 200, 200, 200, 191, 200, 65, 21, 51, 73, 42, 65, 27, 12, 22, 34, 34, 82, 87, 16, 23, 27, 59, 60, 27, 121, 23, 88, 163, 68, 115, 80, 200, 53, 32, 114, 116, 169, 110, 146, 109, 67, 200, 123, 99, 99, 84, 110, 133, 47, 101, 116, 106, 167, 200, 29, 59, 83, 34, 62, 200, 149, 200, 200, 200, 183, 200, 200, 200, 93, 55, 80, 142, 200, 200, 200, 97, 200, 199, 14, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_env_wait_ms': 0.05432742863909169, 'mean_processing_ms': 0.13627080211597847, 'mean_inference_ms': 0.6713560214624098}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 19840, 'num_steps_sampled': 20000, 'sample_time_ms': 2054.579, 'load_time_ms': 13.082, 'grad_time_ms': 2261.387, 'update_time_ms': 131.568, 'learner': {'default_policy': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 340.10638, 'policy_loss': -0.004373678, 'vf_loss': 340.10983, 'vf_explained_var': 0.37318394, 'kl': 0.0029831799, 'entropy': 0.55177253, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 20000, 'episodes_total': 346, 'training_iteration': 5, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-39', 'timestamp': 1584839499, 'time_this_iter_s': 3.8693058490753174, 'time_total_s': 22.367305994033813, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 22.367305994033813, 'timesteps_since_restore': 20000, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 74.16666666666667, 'ram_util_percent': 59.03333333333334}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_5/checkpoint-5\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 14.0, 'episode_reward_mean': 156.88, 'episode_len_mean': 156.88, 'episodes_this_iter': 21, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 169.0, 168.0, 177.0, 200.0, 152.0, 129.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 88.0, 163.0, 68.0, 115.0, 80.0, 200.0, 53.0, 32.0, 114.0, 116.0, 169.0, 110.0, 146.0, 109.0, 67.0, 200.0, 123.0, 99.0, 99.0, 84.0, 110.0, 133.0, 47.0, 101.0, 116.0, 106.0, 167.0, 200.0, 29.0, 59.0, 83.0, 34.0, 62.0, 200.0, 149.0, 200.0, 200.0, 200.0, 183.0, 200.0, 200.0, 200.0, 93.0, 55.0, 80.0, 142.0, 200.0, 200.0, 200.0, 97.0, 200.0, 199.0, 14.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 146.0, 200.0, 200.0, 72.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 169, 168, 177, 200, 152, 129, 200, 200, 200, 200, 200, 200, 88, 163, 68, 115, 80, 200, 53, 32, 114, 116, 169, 110, 146, 109, 67, 200, 123, 99, 99, 84, 110, 133, 47, 101, 116, 106, 167, 200, 29, 59, 83, 34, 62, 200, 149, 200, 200, 200, 183, 200, 200, 200, 93, 55, 80, 142, 200, 200, 200, 97, 200, 199, 14, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 190, 200, 146, 200, 200, 72, 200, 200, 200, 200, 200, 200, 200, 191, 200]}, 'sampler_perf': {'mean_env_wait_ms': 0.054510631903248646, 'mean_processing_ms': 0.13455172506244378, 'mean_inference_ms': 0.6698071992026624}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 23808, 'num_steps_sampled': 24000, 'sample_time_ms': 1962.496, 'load_time_ms': 11.173, 'grad_time_ms': 2290.329, 'update_time_ms': 110.214, 'learner': {'default_policy': {'cur_kl_coeff': 0.15000000596046448, 'cur_lr': 4.999999873689376e-05, 'total_loss': 241.99626, 'policy_loss': -0.006630587, 'vf_loss': 242.00224, 'vf_explained_var': 0.5413472, 'kl': 0.0044688038, 'entropy': 0.5308944, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 24000, 'episodes_total': 367, 'training_iteration': 6, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-43', 'timestamp': 1584839503, 'time_this_iter_s': 3.947899103164673, 'time_total_s': 26.315205097198486, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 26.315205097198486, 'timesteps_since_restore': 24000, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 73.0, 'ram_util_percent': 59.08}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_6/checkpoint-6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': 200.0, 'episode_reward_min': 14.0, 'episode_reward_mean': 174.49, 'episode_len_mean': 174.49, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 196.0, 110.0, 133.0, 47.0, 101.0, 116.0, 106.0, 167.0, 200.0, 29.0, 59.0, 83.0, 34.0, 62.0, 200.0, 149.0, 200.0, 200.0, 200.0, 183.0, 200.0, 200.0, 200.0, 93.0, 55.0, 80.0, 142.0, 200.0, 200.0, 200.0, 97.0, 200.0, 199.0, 14.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 146.0, 200.0, 200.0, 72.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 169.0, 168.0, 177.0, 200.0, 152.0, 129.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196, 110, 133, 47, 101, 116, 106, 167, 200, 29, 59, 83, 34, 62, 200, 149, 200, 200, 200, 183, 200, 200, 200, 93, 55, 80, 142, 200, 200, 200, 97, 200, 199, 14, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 190, 200, 146, 200, 200, 72, 200, 200, 200, 200, 200, 200, 200, 191, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 169, 168, 177, 200, 152, 129, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_env_wait_ms': 0.05408665777796459, 'mean_processing_ms': 0.13262020861743257, 'mean_inference_ms': 0.6643598521161965}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 27776, 'num_steps_sampled': 28000, 'sample_time_ms': 1901.024, 'load_time_ms': 9.737, 'grad_time_ms': 2256.711, 'update_time_ms': 94.971, 'learner': {'default_policy': {'cur_kl_coeff': 0.07500000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 251.3452, 'policy_loss': -0.0032382119, 'vf_loss': 251.34808, 'vf_explained_var': 0.60036075, 'kl': 0.004880876, 'entropy': 0.53875715, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 28000, 'episodes_total': 387, 'training_iteration': 7, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-47', 'timestamp': 1584839507, 'time_this_iter_s': 3.594815969467163, 'time_total_s': 29.91002106666565, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 29.91002106666565, 'timesteps_since_restore': 28000, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 70.58000000000001, 'ram_util_percent': 59.04}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_7/checkpoint-7\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 14.0, 'episode_reward_mean': 187.4, 'episode_len_mean': 187.4, 'episodes_this_iter': 21, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 70.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 93.0, 55.0, 80.0, 142.0, 200.0, 200.0, 200.0, 97.0, 200.0, 199.0, 14.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 146.0, 200.0, 200.0, 72.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 169.0, 168.0, 177.0, 200.0, 152.0, 129.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 196.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 70, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 93, 55, 80, 142, 200, 200, 200, 97, 200, 199, 14, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 190, 200, 146, 200, 200, 72, 200, 200, 200, 200, 200, 200, 200, 191, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 169, 168, 177, 200, 152, 129, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196]}, 'sampler_perf': {'mean_env_wait_ms': 0.05357416011917536, 'mean_processing_ms': 0.13005204326613082, 'mean_inference_ms': 0.6575045349041122}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 31744, 'num_steps_sampled': 32000, 'sample_time_ms': 1854.42, 'load_time_ms': 8.652, 'grad_time_ms': 2239.368, 'update_time_ms': 83.54, 'learner': {'default_policy': {'cur_kl_coeff': 0.03750000149011612, 'cur_lr': 4.999999873689376e-05, 'total_loss': 263.1841, 'policy_loss': -0.0022626207, 'vf_loss': 263.1862, 'vf_explained_var': 0.5832132, 'kl': 0.0049958546, 'entropy': 0.52409, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 32000, 'episodes_total': 408, 'training_iteration': 8, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-50', 'timestamp': 1584839510, 'time_this_iter_s': 3.653904914855957, 'time_total_s': 33.563925981521606, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 33.563925981521606, 'timesteps_since_restore': 32000, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 71.01666666666667, 'ram_util_percent': 59.15}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_8/checkpoint-8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': 200.0, 'episode_reward_min': 70.0, 'episode_reward_mean': 194.6, 'episode_len_mean': 194.6, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 146.0, 200.0, 200.0, 72.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 169.0, 168.0, 177.0, 200.0, 152.0, 129.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 70.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 190, 200, 146, 200, 200, 72, 200, 200, 200, 200, 200, 200, 200, 191, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 169, 168, 177, 200, 152, 129, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 70, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_env_wait_ms': 0.052978042537390815, 'mean_processing_ms': 0.12806427882777152, 'mean_inference_ms': 0.6509308219307787}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 35712, 'num_steps_sampled': 36000, 'sample_time_ms': 1845.502, 'load_time_ms': 7.841, 'grad_time_ms': 2226.844, 'update_time_ms': 74.692, 'learner': {'default_policy': {'cur_kl_coeff': 0.01875000074505806, 'cur_lr': 4.999999873689376e-05, 'total_loss': 270.1362, 'policy_loss': -0.0042740647, 'vf_loss': 270.14035, 'vf_explained_var': 0.5586399, 'kl': 0.007817161, 'entropy': 0.48292312, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 36000, 'episodes_total': 428, 'training_iteration': 9, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-54', 'timestamp': 1584839514, 'time_this_iter_s': 3.9118659496307373, 'time_total_s': 37.475791931152344, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 37.475791931152344, 'timesteps_since_restore': 36000, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 72.63999999999999, 'ram_util_percent': 59.0}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_9/checkpoint-9\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 70.0, 'episode_reward_mean': 196.61, 'episode_len_mean': 196.61, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 169.0, 168.0, 177.0, 200.0, 152.0, 129.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 70.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 169, 168, 177, 200, 152, 129, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 70, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_env_wait_ms': 0.05263392725674126, 'mean_processing_ms': 0.1268703477702121, 'mean_inference_ms': 0.6474018926788065}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 39680, 'num_steps_sampled': 40000, 'sample_time_ms': 1841.67, 'load_time_ms': 7.174, 'grad_time_ms': 2240.193, 'update_time_ms': 67.854, 'learner': {'default_policy': {'cur_kl_coeff': 0.01875000074505806, 'cur_lr': 4.999999873689376e-05, 'total_loss': 258.9732, 'policy_loss': 0.0011369279, 'vf_loss': 258.97195, 'vf_explained_var': 0.55234313, 'kl': 0.0048408736, 'entropy': 0.45569715, 'entropy_coeff': 0.0}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 40000, 'episodes_total': 448, 'training_iteration': 10, 'experiment_id': '71ad611ab28b4d1cabc25647d3748906', 'date': '2020-03-21_18-11-59', 'timestamp': 1584839519, 'time_this_iter_s': 4.179319143295288, 'time_total_s': 41.65511107444763, 'pid': 2939, 'hostname': 'derwen', 'node_ip': '192.168.1.65', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 41.65511107444763, 'timesteps_since_restore': 40000, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 74.7, 'ram_util_percent': 59.6}, 'num_healthy_workers': 2}\n",
      "\n",
      "/tmp/ppo/checkpoint_10/checkpoint-10\n"
     ]
    }
   ],
   "source": [
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"log_level\"] = \"WARN\"\n",
    "\n",
    "n_iter = 10\n",
    "reward_history = []\n",
    "\n",
    "agent = ppo.PPOTrainer(config, env=\"CartPole-v0\")\n",
    "\n",
    "for _ in range(n_iter):\n",
    "    result = agent.train()\n",
    "    print(result)\n",
    "\n",
    "    max_reward = result[\"episode_reward_max\"]\n",
    "    reward_history.append(max_reward)\n",
    "\n",
    "    file_name = agent.save(\"/tmp/ppo\")\n",
    "    print(f\"\\n{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75.0, 145.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]\n"
     ]
    }
   ],
   "source": [
    "print(reward_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gp1LgeCJjGLk"
   },
   "source": [
    "The history of `max_reward` shows that this model `200` by the third iteration -- which is good, since the [*solution*](https://gym.openai.com/envs/CartPole-v0/) for `CartPole-v0` is to get an average reward of `195.0` over a hundred consecutive trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-21 18:13:13,752\tINFO resource_spec.py:212 -- Starting Ray with 4.15 GiB memory available for workers and up to 2.09 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-03-21 18:13:14,122\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8266\u001b[39m\u001b[22m\n",
      "2020-03-21 18:13:14,807\tINFO trainer.py:420 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2020-03-21 18:13:14,840\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\n",
      "2020-03-21 18:13:19,704\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "2020-03-21 18:13:19,802\tWARNING trainable.py:210 -- Getting current IP.\n",
      "2020-03-21 18:13:19,802\tINFO trainable.py:416 -- Restored on 192.168.1.65 from checkpoint: /tmp/ppo/checkpoint_10/checkpoint-10\n",
      "2020-03-21 18:13:19,802\tINFO trainable.py:423 -- Current state after restoring: {'_iteration': 10, '_timesteps_total': 40000, '_time_total': 41.65511107444763, '_episodes_total': 448}\n",
      "\u001b[2m\u001b[36m(pid=3040)\u001b[0m /opt/anaconda3/lib/python3.7/site-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\u001b[2m\u001b[36m(pid=3040)\u001b[0m   obj = yaml.load(type_)\n",
      "\u001b[2m\u001b[36m(pid=3043)\u001b[0m /opt/anaconda3/lib/python3.7/site-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\u001b[2m\u001b[36m(pid=3043)\u001b[0m   obj = yaml.load(type_)\n",
      "Episode #0: reward: 200.0\n",
      "Episode #1: reward: 200.0\n",
      "Episode #2: reward: 200.0\n",
      "Episode #3: reward: 200.0\n",
      "Episode #4: reward: 200.0\n",
      "Episode #5: reward: 200.0\n",
      "Episode #6: reward: 200.0\n",
      "Episode #7: reward: 200.0\n",
      "Episode #8: reward: 200.0\n",
      "Episode #9: reward: 200.0\n"
     ]
    }
   ],
   "source": [
    "! rllib rollout \\\n",
    "    /tmp/ppo/checkpoint_10/checkpoint-10 \\\n",
    "    --config \"{\\\"env\\\": \\\"CartPole-v0\\\"}\" --run PPO \\\n",
    "    --steps 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tI9vJ1vU6Mj1"
   },
   "source": [
    "Now that we've trained a model, we can look at its resulting policy…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "NylH7aYqh72O",
    "outputId": "54469bad-83d0-471c-c036-04d6ca2838d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'default_policy/fc_1/kernel:0' shape=(4, 256) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(4, 256) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 2) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_out/bias:0' shape=(2,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>,\n",
      " <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>]\n",
      "<tf.Tensor 'Reshape:0' shape=(?,) dtype=float32>\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "policy = agent.get_policy()\n",
    "model = policy.model\n",
    "\n",
    "pprint.pprint(model.variables())\n",
    "pprint.pprint(model.value_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "QxLGf4eQGP9Q",
    "outputId": "d9b20198-06cc-444d-bf20-25803c7e8486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observations (InputLayer)       [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fc_1 (Dense)                    (None, 256)          1280        observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc_value_1 (Dense)              (None, 256)          1280        observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc_2 (Dense)                    (None, 256)          65792       fc_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc_value_2 (Dense)              (None, 256)          65792       fc_value_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc_out (Dense)                  (None, 2)            514         fc_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "value_out (Dense)               (None, 1)            257         fc_value_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 134,915\n",
      "Trainable params: 134,915\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.base_model.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of rllib_ppo_dqn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
