{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple contextual bandit example with 3 arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "from ray import tune\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleContextualBandit (gym.Env):\n",
    "    def __init__ (self, config=None):\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(low=-1., high=1., shape=(2, ))\n",
    "        self.cur_context = None\n",
    "\n",
    "    def reset (self):\n",
    "        self.cur_context = random.choice([-1., 1.])\n",
    "        return np.array([self.cur_context, -self.cur_context])\n",
    "\n",
    "    def step (self, action):\n",
    "        rewards_for_context = {\n",
    "            -1.: [-10, 0, 10],\n",
    "            1.: [10, 0, -10],\n",
    "        }\n",
    "        \n",
    "        reward = rewards_for_context[self.cur_context][action]\n",
    "        \n",
    "        return (np.array([-self.cur_context, self.cur_context]), reward, True,\n",
    "                {\n",
    "                    \"regret\": 10 - reward\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit = SimpleContextualBandit()\n",
    "bandit.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 2\n",
      "(array([ 1., -1.]), 10, True, {'regret': 0})\n",
      "action 0\n",
      "(array([ 1., -1.]), -10, True, {'regret': 20})\n",
      "action 2\n",
      "(array([ 1., -1.]), 10, True, {'regret': 0})\n",
      "action 1\n",
      "(array([ 1., -1.]), 0, True, {'regret': 10})\n",
      "action 0\n",
      "(array([ 1., -1.]), -10, True, {'regret': 20})\n",
      "action 0\n",
      "(array([ 1., -1.]), -10, True, {'regret': 20})\n",
      "action 1\n",
      "(array([ 1., -1.]), 0, True, {'regret': 10})\n",
      "action 0\n",
      "(array([ 1., -1.]), -10, True, {'regret': 20})\n",
      "action 2\n",
      "(array([ 1., -1.]), 10, True, {'regret': 0})\n",
      "action 2\n",
      "(array([ 1., -1.]), 10, True, {'regret': 0})\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    obs = bandit.step(bandit.action_space.sample())\n",
    "    print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = {\n",
    "    \"training_iteration\": 200,\n",
    "    \"timesteps_total\": 100000,\n",
    "    \"episode_reward_mean\": 10.0,\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"env\": SimpleContextualBandit,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-25 22:20:45,852\tINFO resource_spec.py:212 -- Starting Ray with 3.81 GiB memory available for workers and up to 1.91 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-05-25 22:20:46,265\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/4 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.27 GiB objects<br>Result logdir: /Users/paco/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                 </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBandit_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=49223)\u001b[0m 2020-05-25 22:20:56,301\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=49223)\u001b[0m 2020-05-25 22:20:56,305\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=49223)\u001b[0m /opt/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=49223)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=49223)\u001b[0m 2020-05-25 22:20:56,368\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=49223)\u001b[0m 2020-05-25 22:20:56,369\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "Result for contrib_LinUCB_SimpleContextualBandit_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-05-25_22-20-56\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 9.9\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 9605be5530a649efb330e6914bb5a8ef\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.317\n",
      "  hostname: derwen\n",
      "  info:\n",
      "    grad_time_ms: 0.317\n",
      "    learner:\n",
      "      cumulative_regret: 10.0\n",
      "      update_latency: 0.00015091896057128906\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 3151.243\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1064.058\n",
      "    sample_time_ms: 0.94\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 10.0\n",
      "    update_latency: 0.00015091896057128906\n",
      "  node_ip: 192.168.1.244\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 3151.243\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 49.1\n",
      "    ram_util_percent: 68.9\n",
      "  pid: 49223\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1064.058\n",
      "  sample_time_ms: 0.94\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.03369727937301786\n",
      "    mean_inference_ms: 0.6675318916245261\n",
      "    mean_processing_ms: 0.38260044437823915\n",
      "  time_since_restore: 0.16234183311462402\n",
      "  time_this_iter_s: 0.16234183311462402\n",
      "  time_total_s: 0.16234183311462402\n",
      "  timestamp: 1590470456\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_SimpleContextualBandit_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-05-25_22-20-56\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 10.0\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 200\n",
      "  experiment_id: 9605be5530a649efb330e6914bb5a8ef\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.348\n",
      "  hostname: derwen\n",
      "  info:\n",
      "    grad_time_ms: 0.348\n",
      "    learner:\n",
      "      cumulative_regret: 10.0\n",
      "      update_latency: 0.0002529621124267578\n",
      "    num_steps_sampled: 200\n",
      "    num_steps_trained: 200\n",
      "    opt_peak_throughput: 2877.146\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1012.677\n",
      "    sample_time_ms: 0.987\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 2\n",
      "  learner:\n",
      "    cumulative_regret: 10.0\n",
      "    update_latency: 0.0002529621124267578\n",
      "  node_ip: 192.168.1.244\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 200\n",
      "  num_steps_trained: 200\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 2877.146\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 49223\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1012.677\n",
      "  sample_time_ms: 0.987\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.03505227577627002\n",
      "    mean_inference_ms: 0.6009915574866148\n",
      "    mean_processing_ms: 0.3762672196573286\n",
      "  time_since_restore: 0.30249667167663574\n",
      "  time_this_iter_s: 0.14015483856201172\n",
      "  time_total_s: 0.30249667167663574\n",
      "  timestamp: 1590470456\n",
      "  timesteps_since_restore: 200\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 200\n",
      "  training_iteration: 2\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.27 GiB objects<br>Result logdir: /Users/paco/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                 </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBandit_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        0.302497</td><td style=\"text-align: right;\"> 200</td><td style=\"text-align: right;\">      10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trials took 10.897155046463013 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "analysis = tune.run(\"contrib/LinUCB\", config=config, stop=stop)\n",
    "\n",
    "print(\"The trials took\", time.time() - start_time, \"seconds\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
